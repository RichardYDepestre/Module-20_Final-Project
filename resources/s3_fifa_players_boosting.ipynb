{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('mlenv': conda)"
  },
  "interpreter": {
   "hash": "c8664c37d20d1a667b792eed6f68d26a151ec74784f499ac31579ebbdd16e46a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Purpose:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1) load encoded datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports.\n",
    "%run s0_fifa_players_functions.ipynb\n",
    "\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "source": [
    "## ---> Modify the location below to fit your dev environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 3879k  100 3879k    0     0  5799k      0 --:--:-- --:--:-- --:--:-- 5799k\n"
     ]
    }
   ],
   "source": [
    "os.chdir('E:\\\\data-engineering@ColumbiaUnv\\\\Module-20_final_project\\\\resources')\n",
    "\n",
    "!curl -L https://raw.githubusercontent.com/ponda614/Data-Science-Final-Project-/main/resources/players.csv  -o fifa_players_git.csv\n",
    "\n",
    "os.chdir('E:\\\\data-engineering@ColumbiaUnv\\\\Module-20_final_project\\\\notebooks')"
   ]
  },
  {
   "source": [
    "# 2) build dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "players_dataset_loc= os.path.join('../resources', 'fifa_players_encoded.csv')\n",
    "players_df = create_fifa_players_dataframe(players_dataset_loc)\n",
    "\n",
    "# display(players_df)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "# 3) Separate features from target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goalkeepers_stats_df = encode_field(goalkeepers_stats_df, 'rating')\n",
    "# goal_keepers_dataset_loc= os.path.join('../resources', 'fifa_goal_keepers_encoded.csv')\n",
    "# goalkeepers_stats_df.to_csv(goal_keepers_dataset_loc, index=False)\n",
    "# display(goalkeepers_stats_df)\n",
    "X = players_df.copy()\n",
    "X = X.drop([\"rating\"], axis=1)\n",
    "\n",
    "Y = players_df['rating'].values\n",
    "\n",
    "# display(array)\n",
    "# # display(goalkeepers_stats_df)\n",
    "# display(Y)\n",
    "# display(X)"
   ]
  },
  {
   "source": [
    "# 4) Splitting into Train and Test sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)\n",
    "# y_train = y.train.ravel()\n",
    "# display(X_train)\n",
    "# display(X_test)\n",
    "# display(y_train)\n",
    "# display(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# display(y_train)\n",
    "# display(X_train_scaled)\n",
    "# display(X_test_scaled)"
   ]
  },
  {
   "source": [
    "# 5) Identify the learning rate that yields the best performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "GradientBoostingClassifier(learning_rate=1, max_depth=30, max_features=29,\n                           n_estimators=25, random_state=10)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "   classifier = GradientBoostingClassifier(n_estimators=40,\n",
    "   learning_rate=learning_rate,\n",
    "   max_features=29,\n",
    "   max_depth=30,\n",
    "   random_state=10)\n",
    "   classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "display(classifier)"
   ]
  },
  {
   "source": [
    "# Making predictions using the Test Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate:  1\nAccuracy score (training): 1.000\nAccuracy score (validation): 0.818\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_train_scaled,\n",
    "           y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_test_scaled,\n",
    "           y_test)))"
   ]
  },
  {
   "source": [
    "# Evaluate the Model and Calculate the accuracy score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score : 0.8782420749279539\n"
     ]
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=0.5, max_features=5, max_depth=3, random_state=0)\n",
    "\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "source": [
    "# Generate confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "          Predicted 0  Predicted 1  Predicted 2\nActual 0         2483            0          166\nActual 1            2           15           13\nActual 2          304           22         1159",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted 0</th>\n      <th>Predicted 1</th>\n      <th>Predicted 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual 0</th>\n      <td>2483</td>\n      <td>0</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>Actual 1</th>\n      <td>2</td>\n      <td>15</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>Actual 2</th>\n      <td>304</td>\n      <td>22</td>\n      <td>1159</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas \n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pandas.DataFrame(\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\", \"Actual 2\"],\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\", \"Predicted 2\"]\n",
    ")\n",
    "display(cm_df)"
   ]
  },
  {
   "source": [
    "# Create Classification report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification Report\n              precision    recall  f1-score   support\n\n           0       0.89      0.94      0.91      2649\n           1       0.41      0.50      0.45        30\n           2       0.87      0.78      0.82      1485\n\n    accuracy                           0.88      4164\n   macro avg       0.72      0.74      0.73      4164\nweighted avg       0.88      0.88      0.88      4164\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}